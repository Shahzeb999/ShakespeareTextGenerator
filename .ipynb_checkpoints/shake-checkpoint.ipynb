{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f4095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "max_length = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"\"\n",
    "training_size=160000\n",
    "test_portion=.1\n",
    "\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a9c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SONNETS_FILE = './sonnets.txt'\n",
    "\n",
    "# Read the data\n",
    "with open('./sonnets.txt') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6444c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = tf.keras.utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5415006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 100)           321100    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 300)          301200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 300)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1605)              162105    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3211)              5156866   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,101,671\n",
      "Trainable params: 6,101,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcbceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "484/484 [==============================] - 51s 91ms/step - loss: 6.9082 - accuracy: 0.0224\n",
      "Epoch 2/100\n",
      "484/484 [==============================] - 49s 101ms/step - loss: 6.5024 - accuracy: 0.0236\n",
      "Epoch 3/100\n",
      "484/484 [==============================] - 51s 105ms/step - loss: 6.4111 - accuracy: 0.0243\n",
      "Epoch 4/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 6.2919 - accuracy: 0.0288\n",
      "Epoch 5/100\n",
      "484/484 [==============================] - 52s 108ms/step - loss: 6.1916 - accuracy: 0.0344\n",
      "Epoch 6/100\n",
      "484/484 [==============================] - 53s 109ms/step - loss: 6.1058 - accuracy: 0.0389\n",
      "Epoch 7/100\n",
      "484/484 [==============================] - 53s 109ms/step - loss: 6.0291 - accuracy: 0.0409\n",
      "Epoch 8/100\n",
      "484/484 [==============================] - 53s 110ms/step - loss: 5.9474 - accuracy: 0.0467\n",
      "Epoch 9/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 5.8444 - accuracy: 0.0515\n",
      "Epoch 10/100\n",
      "484/484 [==============================] - 57s 119ms/step - loss: 5.7291 - accuracy: 0.0568\n",
      "Epoch 11/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 5.6174 - accuracy: 0.0628\n",
      "Epoch 12/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 5.5068 - accuracy: 0.0710\n",
      "Epoch 13/100\n",
      "484/484 [==============================] - 55s 115ms/step - loss: 5.3875 - accuracy: 0.0757\n",
      "Epoch 14/100\n",
      "484/484 [==============================] - 53s 110ms/step - loss: 5.2802 - accuracy: 0.0839\n",
      "Epoch 15/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 5.1689 - accuracy: 0.0897\n",
      "Epoch 16/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 5.0548 - accuracy: 0.0971\n",
      "Epoch 17/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.9487 - accuracy: 0.1076\n",
      "Epoch 18/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 4.8467 - accuracy: 0.1145\n",
      "Epoch 19/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.7382 - accuracy: 0.1255\n",
      "Epoch 20/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 4.6298 - accuracy: 0.1322\n",
      "Epoch 21/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.5241 - accuracy: 0.1449\n",
      "Epoch 22/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.4157 - accuracy: 0.1570\n",
      "Epoch 23/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.3118 - accuracy: 0.1645\n",
      "Epoch 24/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 4.2071 - accuracy: 0.1801\n",
      "Epoch 25/100\n",
      "484/484 [==============================] - 54s 111ms/step - loss: 4.1092 - accuracy: 0.1901\n",
      "Epoch 26/100\n",
      "484/484 [==============================] - 54s 112ms/step - loss: 4.0010 - accuracy: 0.2071\n",
      "Epoch 27/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.8970 - accuracy: 0.2218\n",
      "Epoch 28/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.8018 - accuracy: 0.2394\n",
      "Epoch 29/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.7096 - accuracy: 0.2610\n",
      "Epoch 30/100\n",
      "484/484 [==============================] - 55s 113ms/step - loss: 3.6136 - accuracy: 0.2744\n",
      "Epoch 31/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.5238 - accuracy: 0.2967\n",
      "Epoch 32/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.4316 - accuracy: 0.3177\n",
      "Epoch 33/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.3483 - accuracy: 0.3344\n",
      "Epoch 34/100\n",
      "484/484 [==============================] - 56s 115ms/step - loss: 3.2631 - accuracy: 0.3496\n",
      "Epoch 35/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.1762 - accuracy: 0.3707\n",
      "Epoch 36/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.0979 - accuracy: 0.3860\n",
      "Epoch 37/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 3.0242 - accuracy: 0.4034\n",
      "Epoch 38/100\n",
      "484/484 [==============================] - 56s 115ms/step - loss: 2.9573 - accuracy: 0.4191\n",
      "Epoch 39/100\n",
      "484/484 [==============================] - 56s 115ms/step - loss: 2.8928 - accuracy: 0.4334\n",
      "Epoch 40/100\n",
      "484/484 [==============================] - 56s 116ms/step - loss: 2.8179 - accuracy: 0.4510\n",
      "Epoch 41/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 2.7442 - accuracy: 0.4694\n",
      "Epoch 42/100\n",
      "484/484 [==============================] - 56s 116ms/step - loss: 2.6912 - accuracy: 0.4812\n",
      "Epoch 43/100\n",
      "484/484 [==============================] - 56s 117ms/step - loss: 2.6252 - accuracy: 0.4978\n",
      "Epoch 44/100\n",
      "484/484 [==============================] - 56s 116ms/step - loss: 2.5654 - accuracy: 0.5087\n",
      "Epoch 45/100\n",
      "484/484 [==============================] - 55s 114ms/step - loss: 2.5150 - accuracy: 0.5202\n",
      "Epoch 46/100\n",
      "484/484 [==============================] - 57s 118ms/step - loss: 2.4586 - accuracy: 0.5304\n",
      "Epoch 47/100\n",
      "484/484 [==============================] - 58s 119ms/step - loss: 2.4071 - accuracy: 0.5457\n",
      "Epoch 48/100\n",
      "484/484 [==============================] - 61s 125ms/step - loss: 2.3509 - accuracy: 0.5593\n",
      "Epoch 49/100\n",
      "484/484 [==============================] - 60s 124ms/step - loss: 2.3013 - accuracy: 0.5662\n",
      "Epoch 50/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 2.2514 - accuracy: 0.5817\n",
      "Epoch 51/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 2.2235 - accuracy: 0.5857\n",
      "Epoch 52/100\n",
      "484/484 [==============================] - 58s 119ms/step - loss: 2.1741 - accuracy: 0.5958\n",
      "Epoch 53/100\n",
      "484/484 [==============================] - 58s 120ms/step - loss: 2.1196 - accuracy: 0.6080\n",
      "Epoch 54/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 2.0777 - accuracy: 0.6191\n",
      "Epoch 55/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 2.0473 - accuracy: 0.6253\n",
      "Epoch 56/100\n",
      "484/484 [==============================] - 58s 121ms/step - loss: 2.0109 - accuracy: 0.6331\n",
      "Epoch 57/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.9779 - accuracy: 0.6367\n",
      "Epoch 58/100\n",
      "484/484 [==============================] - 56s 117ms/step - loss: 1.9346 - accuracy: 0.6496\n",
      "Epoch 59/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 1.8963 - accuracy: 0.6588\n",
      "Epoch 60/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 1.8694 - accuracy: 0.6659\n",
      "Epoch 61/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 1.8306 - accuracy: 0.6741\n",
      "Epoch 62/100\n",
      "484/484 [==============================] - 57s 119ms/step - loss: 1.8065 - accuracy: 0.6744\n",
      "Epoch 63/100\n",
      "484/484 [==============================] - 57s 119ms/step - loss: 1.7667 - accuracy: 0.6872\n",
      "Epoch 64/100\n",
      "484/484 [==============================] - 57s 118ms/step - loss: 1.7516 - accuracy: 0.6874\n",
      "Epoch 65/100\n",
      "484/484 [==============================] - 57s 117ms/step - loss: 1.7252 - accuracy: 0.6938\n",
      "Epoch 66/100\n",
      "484/484 [==============================] - 57s 118ms/step - loss: 1.6942 - accuracy: 0.7012\n",
      "Epoch 67/100\n",
      "484/484 [==============================] - 57s 118ms/step - loss: 1.6619 - accuracy: 0.7089\n",
      "Epoch 68/100\n",
      "484/484 [==============================] - 57s 118ms/step - loss: 1.6414 - accuracy: 0.7079\n",
      "Epoch 69/100\n",
      "484/484 [==============================] - 58s 119ms/step - loss: 1.6122 - accuracy: 0.7172\n",
      "Epoch 70/100\n",
      "484/484 [==============================] - 58s 119ms/step - loss: 1.5953 - accuracy: 0.7178\n",
      "Epoch 71/100\n",
      "484/484 [==============================] - 60s 125ms/step - loss: 1.5850 - accuracy: 0.7208\n",
      "Epoch 72/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.5602 - accuracy: 0.7249\n",
      "Epoch 73/100\n",
      "484/484 [==============================] - 59s 121ms/step - loss: 1.5326 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.5009 - accuracy: 0.7407\n",
      "Epoch 75/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.4775 - accuracy: 0.7460\n",
      "Epoch 76/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.4666 - accuracy: 0.7458\n",
      "Epoch 77/100\n",
      "484/484 [==============================] - 59s 123ms/step - loss: 1.4591 - accuracy: 0.7483\n",
      "Epoch 78/100\n",
      "484/484 [==============================] - 59s 123ms/step - loss: 1.4360 - accuracy: 0.7522\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 59s 121ms/step - loss: 1.4186 - accuracy: 0.7536\n",
      "Epoch 80/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.4071 - accuracy: 0.7567\n",
      "Epoch 81/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.3702 - accuracy: 0.7639\n",
      "Epoch 82/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.3537 - accuracy: 0.7683\n",
      "Epoch 83/100\n",
      "484/484 [==============================] - 60s 125ms/step - loss: 1.3683 - accuracy: 0.7631\n",
      "Epoch 84/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.3597 - accuracy: 0.7628\n",
      "Epoch 85/100\n",
      "484/484 [==============================] - 60s 124ms/step - loss: 1.3201 - accuracy: 0.7739\n",
      "Epoch 86/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.3023 - accuracy: 0.7721\n",
      "Epoch 87/100\n",
      "484/484 [==============================] - 59s 122ms/step - loss: 1.3051 - accuracy: 0.7748\n",
      "Epoch 88/100\n",
      "484/484 [==============================] - 59s 123ms/step - loss: 1.2888 - accuracy: 0.7752\n",
      "Epoch 89/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.2586 - accuracy: 0.7847\n",
      "Epoch 90/100\n",
      "484/484 [==============================] - 60s 123ms/step - loss: 1.2395 - accuracy: 0.7866\n",
      "Epoch 91/100\n",
      "484/484 [==============================] - 60s 124ms/step - loss: 1.2406 - accuracy: 0.7865\n",
      "Epoch 92/100\n",
      "484/484 [==============================] - 60s 125ms/step - loss: 1.2267 - accuracy: 0.7897\n",
      "Epoch 93/100\n",
      "484/484 [==============================] - 61s 125ms/step - loss: 1.2204 - accuracy: 0.7912\n",
      "Epoch 94/100\n",
      "484/484 [==============================] - 61s 125ms/step - loss: 1.2126 - accuracy: 0.7894\n",
      "Epoch 95/100\n",
      "484/484 [==============================] - 61s 126ms/step - loss: 1.2162 - accuracy: 0.7893\n",
      "Epoch 96/100\n",
      "484/484 [==============================] - 61s 127ms/step - loss: 1.1894 - accuracy: 0.7914\n",
      "Epoch 97/100\n",
      "484/484 [==============================] - 64s 132ms/step - loss: 1.1736 - accuracy: 0.7979\n",
      "Epoch 98/100\n",
      "484/484 [==============================] - 62s 128ms/step - loss: 1.1556 - accuracy: 0.7954\n",
      "Epoch 99/100\n",
      "484/484 [==============================] - 62s 128ms/step - loss: 1.1500 - accuracy: 0.8012\n",
      "Epoch 100/100\n",
      "484/484 [==============================] - 61s 127ms/step - loss: 1.1450 - accuracy: 0.8004\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac18e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope and dream not see ' ' dyed seen bright green groan dyed boast speed alone forth be am fled free thee doth thee another glory there from true mind ' shown ' behold alone did seen groan did chide their friend ' lived alone did grow speed friend were bright write me one thee so great needing near 'will' ' swearing weak write forth me forth forth bright twain 'will' ' bright aside seen bow moan me seem 'tis thee worms thee well chase praise trust bright all sovereign name bright joy bright away the part of me alone lack forth needing\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope and dream\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\t# Convert the text into sequences\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\t# Pad the sequences\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\t# Get the probabilities of predicting a word\n",
    "\tpredicted = model.predict(token_list, verbose=0)\n",
    "\t# Choose the next word based on the maximum probability\n",
    "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
    "\t# Get the actual word from the word index\n",
    "\toutput_word = tokenizer.index_word[predicted]\n",
    "\t# Append to the current text\n",
    "\tseed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7222a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\bidirectional\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\forward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\forward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\layer\n",
      "......vars\n",
      "...layers\\bidirectional\\layer\\cell\n",
      "......vars\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-13 01:05:41         3808\n",
      "metadata.json                                  2023-02-13 01:05:41           64\n",
      "variables.h5                                   2023-02-13 01:05:42     73270116\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\bidirectional\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\forward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\forward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\layer\n",
      "......vars\n",
      "...layers\\bidirectional\\layer\\cell\n",
      "......vars\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-13 01:05:43         3808\n",
      "metadata.json                                  2023-02-13 01:05:43           64\n",
      "variables.h5                                   2023-02-13 01:05:43     73270116\n"
     ]
    }
   ],
   "source": [
    "#import pickle\n",
    "#pickle.dump(model,open('model.pkl','wb'))\n",
    "#pickle.dump(history,open('history.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41d5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(tokenizer,open('tokenizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e397c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(max_sequence_len,open('max_sequence_len.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
